{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import librosa.display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPool1D, GlobalAvgPool1D, Dropout, BatchNormalization, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_LIB = '~/heartbeat-sounds/'\n",
    "SAMPLE_RATE = 44100\n",
    "CLASSES = ['artifact', 'normal', 'extrahls', 'murmur']\n",
    "CODE_BOOK = {x:i for i,x in enumerate(CLASSES)}   \n",
    "NB_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_filename(fname, string):   \n",
    "    file_name = fname.split('/')[1]\n",
    "    if file_name[:2] == '__':        \n",
    "        file_name = string + file_name\n",
    "    return file_name\n",
    "\n",
    "def load_wav_file(name, path):\n",
    "    _, b = wavfile.read(path + name)\n",
    "    assert _ == SAMPLE_RATE\n",
    "    return b\n",
    "\n",
    "def repeat_to_length(arr, length):\n",
    "    \"\"\"Repeats the numpy 1D array to given length, and makes datatype float\"\"\"\n",
    "    result = np.empty((length, ), dtype = 'float32')\n",
    "    l = len(arr)\n",
    "    pos = 0\n",
    "    while pos + l <= length:\n",
    "        result[pos:pos+l] = arr\n",
    "        pos += l\n",
    "    if pos < length:\n",
    "        result[pos:length] = arr[:length-pos]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(INPUT_LIB + 'set_a.csv')\n",
    "df['fname'] = df['fname'].apply(clean_filename, string='Aunlabelledtest')\n",
    "df['label'].fillna('unclassified')\n",
    "# Load wav file in /clean_a, wav file that undergo lowpass filter\n",
    "df['time_series'] = df['fname'].apply(load_wav_file, path=INPUT_LIB + 'clean_a/' + str('N_'))    \n",
    "df['len_series'] = df['time_series'].apply(len)\n",
    "MAX_LEN = max(df['len_series'])\n",
    "df['time_series'] = df['time_series'].apply(repeat_to_length, length=MAX_LEN)\n",
    "\n",
    "# print(df['time_series'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.stack(df['time_series'].values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# Create a label (category) encoder object\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Fit the encoder to the pandas column\n",
    "\n",
    "\n",
    "labels = df['label'].tolist()\n",
    "le.fit(labels)\n",
    "labels = le.transform(labels)\n",
    "labels = labels.tolist()\n",
    "print(labels)\n",
    "\n",
    "# 0 = 'artifact'\n",
    "# 1 = 'extrahls'\n",
    "# 2 = 'murmur'\n",
    "# 3 = 'normal'\n",
    "\n",
    "print(len(labels))\n",
    "\n",
    "#for i in range(len(labels)):\n",
    "#    if labels[i] != 3:\n",
    "#        new_labels.append(labels[i])\n",
    "\n",
    "#print(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#labels = np.array(labels, dtype='int')\n",
    "#y_data = np_utils.to_categorical(labels)\n",
    "\n",
    "#print(y_data)\n",
    "\n",
    "y_data = labels\n",
    "\n",
    "# print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test, train_filenames, test_filenames = train_test_split(x_data, y_data, df['fname'].values, test_size=0.25)\n",
    "\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import decimate\n",
    "x_train = decimate(x_train, 8, axis=1, zero_phase=True)\n",
    "x_train = decimate(x_train, 8, axis=1, zero_phase=True)\n",
    "x_train = decimate(x_train, 4, axis=1, zero_phase=True)\n",
    "x_test = decimate(x_test, 8, axis=1, zero_phase=True)\n",
    "x_test = decimate(x_test, 8, axis=1, zero_phase=True)\n",
    "x_test = decimate(x_test, 4, axis=1, zero_phase=True)\n",
    "\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale each observation to unit variance, it should already have mean close to zero.\n",
    "x_train = x_train / np.std(x_train, axis=1).reshape(-1,1)\n",
    "x_test = x_test / np.std(x_test, axis=1).reshape(-1,1)\n",
    "\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.290322580645\n"
     ]
    }
   ],
   "source": [
    "#Import Library\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.NuSVC(kernel='linear') \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_train, y_train)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)\n",
    "\n",
    "print (accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
